# from dotenv import load_dotenv
import dashscope
from dashscope.audio.tts import SpeechSynthesizer

dashscope.api_key='sk-01f79255de394c22a8ca88b96a0afaf1'

from moviepy.editor import VideoFileClip,AudioFileClip
from moviepy.audio.io.AudioFileClip import AudioFileClip

import cv2
import base64
import io
import openai
import os
import requests
import streamlit as st
import tempfile

# load_dotenv()

##1.Turn video into frames
def video_to_frames(video_file):
    #save the upload video file to a temporary file
    with tempfile.NamedTemporaryFile(delete=False,suffix='.mp4') as tmpfile:
        tmpfile.write(video_file.read())
        video_filename=tmpfile.name
    
    video_duration=VideoFileClip(video_filename).duration
    video=cv2.VideoCapture(video_filename)
    base64Frame=[]
    
    while video.isOpened():
        success, frame=video.read()
        if not success:
            break
        _,buffer=cv2.imencode('.jpg',frame)
        base64Frame.append(base64.b64encode(buffer).decode("utf-8"))
    
    video.release()
    print(len(base64Frame),"frames read.")
    return base64Frame,video_filename,video_duration

def download_audio(url):
    try:
        # å‘é€ GET è¯·æ±‚ä¸‹è½½éŸ³é¢‘æ–‡ä»¶
        response = requests.get(url, stream=True)
        response.raise_for_status()

        # åˆ›å»ºä¸€ä¸ªä¸´æ—¶ç›®å½•
        temp_dir = tempfile.mkdtemp()

        # æå–æ–‡ä»¶å
        filename = url.split("/")[-1]

        # æ‹¼æ¥ä¿å­˜è·¯å¾„
        file_path = f"{temp_dir}/{filename}"

        # å°†æ–‡ä»¶ä¿å­˜åˆ°ä¸´æ—¶ç›®å½•
        with open(file_path, "wb") as file:
            for chunk in response.iter_content(chunk_size=8192):
                file.write(chunk)

        return file_path

    except Exception as e:
        print(f"ä¸‹è½½éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {e}")
        return None

##2.Generate stories based on frames with gpt4v
def frames_to_story(base64Frames,prompt,api_key):
    PROMPT_MESSAGES=[
        {
            "role":"user",
            "content":[
                prompt,
                *map(lambda x:{"image":x,"resize":768},base64Frames[0::50]),
            ],
        },
    ]
    params={
        "model":"gpt-4-vision-preview",
        "messages":PROMPT_MESSAGES,
        "api_key":api_key,
        "headers":{"Openai-Version":"2020-11-07"},
        "max_tokens":500,
    }
    result=openai.ChatCompletion.create(**params)
    print(result.choices[0].message.content)
    return result.choices[0].message.content
##3.Generate voice over from stories
def text_to_audio(text,api_key,voice):
    response=requests.post(
        "https://api.openai.com/v1/audio/speech",
        headers={
            "Authorization":f"Bearer {api_key}",
        },
        json={
            "model":"tts-1",
            "input":text,
            "voice":voice,
            # "voice":"alloy",
        },
    )
    
    # nova å¥³å¹´è½»
    # alloy ç”·
    # alloy echo fable onyx nova shimmer
    
    #Check if the request was successful
    if response.status_code != 200:
        raise Exception("Request failed with status code")
    
    #Create an in-memory bytes buffer
    audio_bytes_io=io.BytesIO()
    #Write audio data to the in-memory bytes buffer
    for chunk in response.iter_content(chunk_size=1024*1024):
        audio_bytes_io.write(chunk)
        
    #Important : Seek to the start of the BytesIO buffer before returning
    audio_bytes_io.seek(0)
    
    #save audio to a temporary file
    with tempfile.NamedTemporaryFile(suffix=".wav",delete=False) as tmpfile:
        for chunk in response.iter_content(chunk_size=1024*1024):
            tmpfile.write(chunk)
        audio_filename=tmpfile.name
    
    return audio_filename,audio_bytes_io
##4.Merge videos & audio taudio_bytes_io
def merge_audio_video(video_filename,audio_filename,output_filename):
    print("Merging audio and video ...")
    #load the video file
    video_clip=VideoFileClip(video_filename)
    #load the audio file
    audio_clip=AudioFileClip(audio_filename)
    #set the audio of the video clip as the audio file
    final_clip=video_clip.set_audio(audio_clip)
    #write the result to a file (without audio)
    final_clip.write_videofile(output_filename,codec='libx264',audio_codec="aac")
    #close the clips
    video_clip.close()
    audio_clip.close()
    
    #return the path to the new video file
    return output_filename
##5.Streamlit UI
def main():
    st.set_page_config(page_title="xRunda GPT4V Demo Video Story Generator",page_icon="ğŸ¥")
    st.header("xRunda GPT4V Demo :bird:")
    
    openai_key=st.text_input("è¾“å…¥ä½ çš„ OpenAI API key",type="password")
    if openai_key in ["",None]:
        st.write("API key ä¸èƒ½ä¸ºç©º")
        exit()
        
    uploaded_file=st.file_uploader("é€‰æ‹©è§†é¢‘æ–‡ä»¶",type=["mp4","avi"])

    option = st.selectbox(
    'é€‰æ‹©ä½ æƒ³è¦çš„éŸ³æ•ˆ',
    ('ä¸œåŒ—å¥³å£°', 'ç”·å£°', 'æ˜å“¥', 'å…‰å“¥', 'æ™®é€šè¯'))
    classify = '';
    if option == 'ç”·å£°':
        classify = 'echo';
    elif option == 'ä¸œåŒ—å¥³å£°':
        classify = 'dongbeinv';
        st.write("è¯•å¬é“¾æ¥ï¼šhttps://res.xrunda.com/paper-tts/1705027721wncoHt.mp3")
    elif option == 'æ˜å“¥':
        classify = 'ming';
        st.write("è¯•å¬é“¾æ¥ï¼šhttps://res.xrunda.com/paper-tts/1705027124nTvciZ.mp3")
    elif option == 'å…‰å“¥':
        classify = 'guang';
        st.write("è¯•å¬é“¾æ¥ï¼šhttps://res.xrunda.com/paper-tts/1705027189XDdwWl.mp3")
    elif option == 'æ™®é€šè¯':
        classify = 'custom';
        st.write("è¯•å¬é“¾æ¥ï¼šhttps://res.xrunda.com/paper-tts/1705027238xJ48m5.mp3")
    # elif option == 'xxx':
    #     classify = 'onyx';
    if uploaded_file is not None:
        st.video(uploaded_file)
        # p='These are demonstration videos of the traditional woodworking piecing process.Create a short voiceover script that can be used along this video.'
        # p='è¿™äº›éƒ½æ˜¯ä¼ ç»Ÿæœ¨å·¥æ‹¼æ¥å·¥è‰ºçš„æ¼”ç¤ºè§†é¢‘ã€‚åˆ¶ä½œä¸€ä¸ªç®€çŸ­çš„ä¸­æ–‡é…éŸ³è„šæœ¬ï¼Œé…åˆè§†é¢‘ä¸­çš„ç”»é¢åšå†…å®¹æè¿°ï¼Œä¸è¯¥è§†é¢‘ä¸€èµ·ä½¿ç”¨ã€‚'
        # p='è¿™æ˜¯ä¸€ä¸ªå„¿ç«¥æ‰‹å·¥åˆ¶ä½œè§†é¢‘ã€‚ç”Ÿæˆä¸€ä¸ªç®€çŸ­çš„ä¸­æ–‡é…éŸ³è„šæœ¬ï¼Œé…åˆè§†é¢‘ä¸­çš„ç”»é¢åšå†…å®¹æè¿°ï¼Œä¸è¯¥è§†é¢‘ä¸€èµ·ä½¿ç”¨ã€‚å†…å®¹å°½é‡æ´»æ³¼è½»æ¾ï¼Œä¸è¦è¿‡äºä¸¥è‚ƒã€‚'
        p='ä¸ºè§†é¢‘ç”Ÿæˆä¸€ä¸ªç®€çŸ­çš„ä¸­æ–‡é…éŸ³è„šæœ¬ï¼Œé…åˆè§†é¢‘ä¸­çš„ç”»é¢åšå†…å®¹æè¿°ï¼Œä¸è¯¥è§†é¢‘ä¸€èµ·ä½¿ç”¨ã€‚å†…å®¹å°½é‡æ´»æ³¼è½»æ¾ï¼Œä¸è¦è¿‡äºä¸¥è‚ƒã€‚'
        # p='è¿™äº›æ˜¯é’å¹´æ²¹ç”»å®¶é™ˆæ›™ä¸¹çš„æ²¹ç”»ä½œå“ï¼Œç”Ÿæˆä¸€ä¸ªç®€çŸ­çš„ä¸­æ–‡é…éŸ³è„šæœ¬ï¼Œé€ä¸€è®²è§£å’Œåˆ†æä¸€ä¸‹æ¯å¹…ä½œå“çš„ç”»é¢ç¾æ„Ÿå’Œè‰ºæœ¯æ€§ï¼Œä»¥åŠä½œè€…åœ¨åˆ›ä½œæ—¶å€™çš„æ€æƒ³çŠ¶æ€ã€‚é…åˆè§†é¢‘ä¸­çš„ç”»é¢åšå†…å®¹æè¿°ï¼Œä¸è¯¥è§†é¢‘ä¸€èµ·ä½¿ç”¨ã€‚ç›´æ¥ç”Ÿæˆé…éŸ³è„šæœ¬ï¼Œä¸è¦å›ç­”æˆ‘ï¼Œè¯·ç›´æ¥å¼€å§‹ç”Ÿæˆã€‚'
        # p='These are frames of a quick product demo walkthrough.Create a short voiceover script that can be used along this video.'
        prompt=st.text_area(
            "Prompt",value=p
        )
    
    
    if st.button("ç”Ÿæˆ",type="primary") and uploaded_file is not None:
        with st.spinner("ç”Ÿæˆä¸­..."):
            base64Frame,video_filename,video_duration=video_to_frames(uploaded_file)
            if video_duration > 60:
                e = RuntimeError('è§†é¢‘è¶…é•¿ä¼šå¯¼è‡´ç”Ÿæˆå¤±è´¥ï¼Œè¯·é€‰æ‹©ä¸€åˆ†é’Ÿä»¥å†…çš„è§†é¢‘')
                st.exception(e)
                exit()
            est_word_count=video_duration
            # est_word_count=video_duration*4
            final_prompt=prompt+f"(This video is ONLY {video_duration} seconds long.so make sure the voice over MUST be able to be explained in less that {est_word_count} words).Don't answer me, please start generating directly"
            text=frames_to_story(base64Frame,final_prompt,openai_key)
            # if 'text' not in st.session_state:
            #     st.session_state['text'] = text
            # if 'text' not in st.session_state:
            #     st.session_state.key = text
            st.write(text)
            if text is not None:
                st.write('(ç”Ÿæˆæ–‡æ¡ˆå¦‚æœä¸æ­£ç¡®æˆ–ä¸æ»¡æ„ï¼Œæ‚¨å¯ä»¥é‡æ–°ç‚¹å‡»ç”Ÿæˆ)')
                if classify == 'ming':
                    response=requests.post(
                        "https://podcast-ai.xrunda.com/api/com_tts",
                        headers={
                            "Content-Type": "application/x-www-form-urlencoded;charset=utf-8", # æŒ‡å®šè¯·æ±‚ä½“ä¸ºJSONæ ¼å¼
                        },
                        data={
                            "text":text,
                            "voice":"DS-Ming"
                        },
                    )
                    st.write('å·²ä¸ºæ‚¨ç”ŸæˆéŸ³é¢‘ä¸å­—å¹•ï¼Œè¯·ç‚¹å‡»é“¾æ¥æŸ¥çœ‹')
                    voice = response.json()
                    st.write('éŸ³é¢‘ï¼š' + voice['data'][0])
                    st.write('å­—å¹•ï¼š' + voice['data'][1])
                    # è·å–ä¸‹è½½å¥½çš„éŸ³é¢‘å’Œè§†é¢‘æ–‡ä»¶
                    # filePath = download_audio('https://res.xrunda.com/paper-tts/1704958137gBj9fl.mp3')
                    filePath = download_audio(voice['data'][0])
                    output_video_filename=os.path.splitext(video_filename)[0]+"_output.mp4"
                    final_video_filename=merge_audio_video(video_filename,filePath,output_video_filename)
                    #display the result
                    st.video(final_video_filename)
                    
                    #clean up the temporary files
                    os.unlink(video_filename)
                    os.unlink(filePath)
                    os.unlink(final_video_filename)
                elif classify == 'guang':
                    response=requests.post(
                        "https://podcast-ai.xrunda.com/api/com_tts",
                        headers={
                            "Content-Type": "application/x-www-form-urlencoded;charset=utf-8", # æŒ‡å®šè¯·æ±‚ä½“ä¸ºJSONæ ¼å¼
                        },
                        data={
                            "text":text,
                            "voice":"DS-Guang"
                        },
                    )
                    st.write('å·²ä¸ºæ‚¨ç”ŸæˆéŸ³é¢‘ä¸å­—å¹•ï¼Œè¯·ç‚¹å‡»é“¾æ¥æŸ¥çœ‹')
                    voice = response.json()
                    st.write('éŸ³é¢‘ï¼š' + voice['data'][0])
                    st.write('å­—å¹•ï¼š' + voice['data'][1])
                    # è·å–ä¸‹è½½å¥½çš„éŸ³é¢‘å’Œè§†é¢‘æ–‡ä»¶
                    filePath = download_audio(voice['data'][0])
                    output_video_filename=os.path.splitext(video_filename)[0]+"_output.mp4"
                    final_video_filename=merge_audio_video(video_filename,filePath,output_video_filename)
                    #display the result
                    st.video(final_video_filename)
                    
                    #clean up the temporary files
                    os.unlink(video_filename)
                    os.unlink(filePath)
                    os.unlink(final_video_filename)
                elif classify == 'custom':
                    response=requests.post(
                        "https://podcast-ai.xrunda.com/api/com_tts",
                        headers={
                            "Content-Type": "application/x-www-form-urlencoded;charset=utf-8", # æŒ‡å®šè¯·æ±‚ä½“ä¸ºJSONæ ¼å¼
                        },
                        data={
                            "text":text,
                            "voice":"zh-CN-YunyangNeural",
                            "rate":"5",
                            "volume":"5",
                        },
                    )
                    st.write('å·²ä¸ºæ‚¨ç”ŸæˆéŸ³é¢‘ä¸å­—å¹•ï¼Œè¯·ç‚¹å‡»é“¾æ¥æŸ¥çœ‹')
                    voice = response.json()
                    st.write('éŸ³é¢‘ï¼š' + voice['data'][0])
                    st.write('å­—å¹•ï¼š' + voice['data'][1])
                    # è·å–ä¸‹è½½å¥½çš„éŸ³é¢‘å’Œè§†é¢‘æ–‡ä»¶
                    filePath = download_audio(voice['data'][0])
                    output_video_filename=os.path.splitext(video_filename)[0]+"_output.mp4"
                    final_video_filename=merge_audio_video(video_filename,filePath,output_video_filename)
                    #display the result
                    st.video(final_video_filename)
                    
                    #clean up the temporary files
                    os.unlink(video_filename)
                    os.unlink(filePath)
                    os.unlink(final_video_filename)
                elif classify == 'dongbeinv':
                    response=requests.post(
                        "https://podcast-ai.xrunda.com/api/com_tts",
                        headers={
                            "Content-Type": "application/x-www-form-urlencoded;charset=utf-8", # æŒ‡å®šè¯·æ±‚ä½“ä¸ºJSONæ ¼å¼
                        },
                        data={
                            "text":'ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Œè¿™é‡Œæ˜¯ä¸€æ¶¦ä¸€è¾¾ä¸ºæ‚¨æ’­æŠ¥ä»Šå¤©çš„å¤©æ°”ï¼ŒåŒ—äº¬ä»Šå¤©æ™´ï¼Œæœ€é«˜æ°”æ¸©å››æ‘„æ°åº¦ï¼Œæœ€ä½æ°”æ¸©é›¶ä¸‹å…­æ‘„æ°åº¦',
                            "voice":"zh-CN-liaoning-XiaobeiNeural",
                            "rate":"5",
                            "volume":"5",
                        },
                    )
                    st.write('å·²ä¸ºæ‚¨ç”ŸæˆéŸ³é¢‘ä¸å­—å¹•ï¼Œè¯·ç‚¹å‡»é“¾æ¥æŸ¥çœ‹')
                    voice = response.json()
                    st.write('éŸ³é¢‘ï¼š' + voice['data'][0])
                    st.write('å­—å¹•ï¼š' + voice['data'][1])
                    # è·å–ä¸‹è½½å¥½çš„éŸ³é¢‘å’Œè§†é¢‘æ–‡ä»¶
                    filePath = download_audio(voice['data'][0])
                    output_video_filename=os.path.splitext(video_filename)[0]+"_output.mp4"
                    final_video_filename=merge_audio_video(video_filename,filePath,output_video_filename)
                    #display the result
                    st.video(final_video_filename)
                    
                    #clean up the temporary files
                    os.unlink(video_filename)
                    os.unlink(filePath)
                    os.unlink(final_video_filename)
                else:
                    # response=requests.post(
                    #     "https://podcast-ai.xrunda.com/api/com_tts",
                    #     headers={
                    #         "Content-Type": "application/x-www-form-urlencoded;charset=utf-8", # æŒ‡å®šè¯·æ±‚ä½“ä¸ºJSONæ ¼å¼
                    #     },
                    #     data={
                    #         "text":text,
                    #         "voice":"zh-CN-YunyangNeural",
                    #         "rate":"5",
                    #         "volume":"5",
                    #     },
                    # )
                    # st.write('å·²ä¸ºæ‚¨ç”ŸæˆéŸ³é¢‘ä¸å­—å¹•ï¼Œè¯·ç‚¹å‡»é“¾æ¥æŸ¥çœ‹')
                    # voice = response.json()
                    # st.write('éŸ³é¢‘ï¼š' + voice['data'][0])
                    # st.write('å­—å¹•ï¼š' + voice['data'][1])
                    #Generate audio from text
                    audio_filename,audio_bytes_io=text_to_audio(text,openai_key,classify)
                    #merge audio and video
                    output_video_filename=os.path.splitext(video_filename)[0]+"_output.mp4"

                    final_video_filename=merge_audio_video(video_filename,audio_filename,output_video_filename)
                    

                    #display the result
                    st.video(final_video_filename)
                    
                    #clean up the temporary files
                    os.unlink(video_filename)
                    os.unlink(audio_filename)
                    os.unlink(final_video_filename)
if __name__=="__main__":
    main()